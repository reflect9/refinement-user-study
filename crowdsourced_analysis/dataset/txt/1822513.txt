can humanity survive? want to bet on it?   sixty ago years, a group of physicists concerned about nuclear weapons created the doomsday clock and set its hands at seven minutes to midnight. now, the clock's keepers, alarmed by new dangers like climate change, have moved the hands up to 11:55 p.m.  my first reaction was a sigh of relief. after all, the 1947 doomsday prediction marked the start of a golden age. never have so many humans lived so long -- and maybe never so peacefully -- as during the past 60 years. the per-capita rate of violence, particularly in the west, seems remarkably low by historical standards. if the clock's keepers are worried once again, their track record suggests we're in for even happier days.  but there's one novel twist that gives me pause. when the bulletin of the atomic scientists announced two weeks ago in washington that it was adjusting the clock, it was joined in a trans-atlantic press conference by scientists at the royal society in london. one of them was the society's president, martin rees, a new breed of doomsayer.  dr. rees, a cosmologist at cambridge and britain's astronomer royal, doesn't just issue gloomy predictions. he doesn't just move the hands of an imaginary and inscrutable clock. (its keepers have never explained what one of their minutes equals on anyone else's clock or calendar.)  no, dr. rees is braver. he gives odds on doomsday and offers to bet on disaster. in his 2003 book, ''our final hour,'' he gives civilization no more than a 50 percent chance of surviving until 2100.  dr. rees is not a knee-jerk technophobe -- he expects great advances as researchers around the world link their knowledge -- but he fears that progress will be undone by what he calls the new global village idiots. he's sure enough of himself to post an offer on long bets, a clever innovation on the web that stewart brand helped start with money from jeff bezos, the founder of amazon.com.  long bets is a nonprofit foundation that calls itself an ''arena for competitive, accountable predictions.'' it lets anyone make a prediction and take wagers on it, with the proceeds going to a charity named by the winner. the bets made so far are from $200 to $10,000, on topics ranging from the driving habits of americans in 2010 to whether the universe will stop expanding. mitchell kapor, the software guru, is betting that in 2029 no computer will have passed the turing test (by conversing so much like a human that you couldn't tell the difference). the physicist freeman dyson's money is on the first extraterrestrial life's being found somewhere other than a planet or its satellite.  five years ago, dr. rees posted this prediction: ''by 2020, bioterror or bioerror will lead to one million casualties in a single event.'' he reasoned that ''by 2020 there will be thousands -- even millions -- of people with the capability to cause a catastrophic biological disaster. my concern is not only organized terrorist groups, but individual weirdos with the mindset of the people who now design computer viruses.''  he didn't get any takers on longbets.org, which seems to me a missed opportunity. so i've posted an offer there to bet him $200 -- not a huge sum, but enough to put both our reputations on the line. i realize that betting on disaster may sound ghoulish, but neither of us will personally profit (if i win, the money goes to the international red cross). and i think bets like this serve a purpose.  besides stimulating public debate, they focus the issue and discipline prophets. no matter how good their intentions, prophets face strong temptations to hype. in the current issue of the bulletin of the atomic scientists, dr. rees wryly describes what happened in 2003 when he turned in a manuscript titled, ''our final century?''  ''my british publisher removed the question mark from the book's title,'' he recalls, ''and the u.s. publisher changed it to 'our final hour.' pessimism, it seems, makes for better marketing.''  it doesn't make for better public policy though. heralds of the bioterror apocalypse have actually worsened the problem of bioterror, as milton leitenberg points out in a 2005 report for the strategic studies institute of the united states army war college.  mr. leitenberg is a scholar at the university of maryland who has been studying biological weapons for decades -- and debunking wild predictions. dr. rees is not alone. senator bill frist called bioterrorism ''the greatest existential threat we have in the world today'' and urged a military effort that ''even dwarfs the manhattan project.''  such rhetoric, mr. leitenberg says, has had the perverse effect of encouraging terrorists to seek out biological weapons. but despite the much-publicized attempts of al qaeda and a japanese group to go biological, terrorists haven't had much luck, because it's still quite hard for individuals or nongovernmental groups to obtain, manufacture or deploy biological weapons of mass destruction.  mr. leitenberg says the biggest threat is of a state deploying biological weapons, and he notes the encouraging decline in the number of countries working on this technology. meanwhile, though, america has been so spooked by the horror-movie scenarios that it's pouring money into defense against biological weapons. dr. leitenberg says that's a mistake, both because it diverts resources from more serious threats -- like natural diseases and epidemics -- and because it could start a new biological arms race as other countries understandably fear that the united states is doing more than just playing defense.  it's possible, as dr. rees fears, that terrorists will get a lot more sophisticated at biotech in the next decade, or that researchers will make some terrible mistake. the technology is getting cheaper and spreading rapidly. but so are the tools for preventing and coping with mistakes.  whatever happens, i don't expect biotechnology to pose an ''existential threat.'' the disaster predicted by dr. rees would be horrific, but humanity has survived worse, like the flu epidemic of 1918 that killed tens of millions of people. i know there are fears of new microorganisms or nanobots gobbling up our species, but i'm confident we'd somehow stop the doomsday clock from striking midnight.  in fact, the wager i'd really like to make with dr. rees is that we'll make it to 2100. i've posted that prediction on long bets, and i'd be glad to give him better odds than the 50-50 chance he gives civilization of surviving the century.  i even think one of us might survive to see the payoff, although my techno-optimism has its limits. i hope some version of me will be around in 2100, but i wouldn't bet on it.  findings  